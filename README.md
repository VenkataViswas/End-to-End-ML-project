From Raw Data to Deployment: An End-to-End ML Project ğŸš€

This repository contains a clean, modular, end-to-end machine learning pipeline that takes raw data, processes it, trains and evaluates models, and prepares them for deployment.

The project is structured to follow best practices, enabling reproducibility, clarity, and CI/CD readiness for ML workflows.

----------------------------------------
ğŸ“Œ Project Highlights

- End-to-end pipeline: data ingestion â†’ cleaning â†’ feature engineering â†’ training â†’ evaluation
- Modular code structure for maintainability
- Logging for traceability
- Configuration management for flexible experimentation
- CI/CD using GitHub Actions with custom AWS EC2 runners
- Jupyter notebooks for EDA and experimentation
- Ready for MongoDB integration in future iterations

----------------------------------------
```plaintext ğŸ—‚ï¸ Project Structure End-to-End-ML-Project/ | â”œâ”€â”€ .github/workflows/ # GitHub Actions workflows for CI/CD â”œâ”€â”€ config/ # Configuration files (YAML/JSON) â”œâ”€â”€ logs/ # Log files for pipeline runs â”œâ”€â”€ notebooks/ # Jupyter notebooks for EDA and experiments â”œâ”€â”€ src/ # Source code for ML pipeline â”‚ â”œâ”€â”€ __init__.py â”‚ â”œâ”€â”€ data_ingestion.py â”‚ â”œâ”€â”€ data_transformation.py â”‚ â”œâ”€â”€ model_trainer.py â”‚ â”œâ”€â”€ model_evaluation.py â”‚ â””â”€â”€ utils.py â”œâ”€â”€ requirements.txt # Python dependencies â”œâ”€â”€ setup.py # Makes project pip-installable â”œâ”€â”€ app.py #  Entry point for starting the pipeline and serving the model â”œâ”€â”€ README.md # Project documentation â””â”€â”€ .gitignore ```

----------------------------------------
âš™ï¸ Features

- Data Ingestion: Load raw data, store intermediate files.
- Data Cleaning & Feature Engineering: Handle missing values, encode categorical variables, scale numerical features.
- Model Training & Evaluation: Train ML models and evaluate using cross-validation and performance metrics.
- Logging: Track pipeline steps, errors, and experiment metadata.
- CI/CD: Automatic linting, testing, and checks using GitHub Actions.
- Modularity: Easy to extend or replace pipeline components.
- Future Ready: MongoDB can be integrated for data storage and experiment tracking.

----------------------------------------
ğŸš€ Getting Started

1ï¸âƒ£ Clone the repository
    git clone https://github.com/VenkataViswas/End-to-End-ML-project.git
    cd End-to-End-ML-project

2ï¸âƒ£ Create a virtual environment and activate it
    python -m venv venv
    source venv/bin/activate   # On Windows: venv\Scripts\activate

3ï¸âƒ£ Install dependencies
    pip install -r requirements.txt

4ï¸âƒ£ Run the flask application to start pipeline and open an webpage
    python application.py

----------------------------------------
ğŸ“Š Exploratory Data Analysis

EDA notebooks are available in the notebooks/ folder to:
- Understand data distributions.


----------------------------------------
ğŸš¦ CI/CD Pipeline

- Configured using GitHub Actions with:
    - Standard runners for lightweight checks.
    - Custom AWS EC2 runners for heavier jobs.
- Automates code linting, testing, and ensures stable builds.

----------------------------------------

â­ If you find this repository helpful, please consider starring it!
